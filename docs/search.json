[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STAT244SC",
    "section": "",
    "text": "Making a quarto website"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About me",
    "section": "",
    "text": "Hey! My name is Bhargavi. I am a sophomore studying computer science and mathematics at Mount Holyoke College. I am interested in machine learning and causal inference.\nFeel free to connect with me on LinkedIn.\n\n\n\nI love taking photos, especially of my friends :D"
  },
  {
    "objectID": "test.html",
    "href": "test.html",
    "title": "STAT244SC Project",
    "section": "",
    "text": "We chose to explore the Breast Cancer Wisconsin (Diagnostic) dataset. The data set has information on the characteristics of various breast masses. The features are calculated from the digitized image of a fine needle aspirate (FNA) of the breast mass. A consecutive series of 569 tumors (212 malignant, 357 benign) provided the data to develop (train) the algorithm. We think the source of our data is reliable as the data was obtained from the University of Wisconsin Hospitals, Madison from Dr. William H. Wolberg.\nThe data set has 568 rows and 32 columns. Each row corresponds to a breast mass, while each column refers to a characteristic feature. We are interested in five variables. Four of these are quantitative:\\ - perimeter_mean: the mean size of the core tumor (mm)\\ - texture_mean: the mean standard deviation of gray-scale values (pixel)\\ - smoothness_mean: the local variation in radius lengths (mm)\\ - concavity_mean: the mean of severity of concave portions of the contour (mm)\\\nThe remaining variable is categorical: Diagnosis (M = malignant, B = benign)."
  },
  {
    "objectID": "test.html#cross-validation",
    "href": "test.html#cross-validation",
    "title": "STAT244SC Project",
    "section": "1. Cross Validation",
    "text": "1. Cross Validation\nCross-validation is a class of methods that estimate the test error by rate by holding out a subset of the training observations from the fitting process, and then applying the statistical learning method to those held out observations.\n\\[\\text{CV}_{(k)} = \\frac{1}{k} \\sum_{j=1}^k \\text{MAE}_j\\]\nThe goal of cross-validation is to test the model’s ability to predict new data that was not used in estimating it, in order to flag problems like overfitting or selection bias and to give insight into how the model will generalize to an independent data set. Overﬁtting occurs when a model reads too much into chance features and essentially memorizes features of the data used to build it, thus reducing reliability and the ability to generalize to underrepresented populations. Cross-validation helps prevent this by providing a more reliable estimate of how well a model would generalize to unseen data.\nWe utilized a linear regression model to build and evaluate a predictive model of breast mass perimeter by concavity.\nWe incorporated 1 predictor, 2 predictors, and then 10 predictors to our model of breast mass perimeter:\n\\[\\mathbb{E}(perimeter\\_mean| concavity\\_mean) = β_0+ β_1(concavity\\_mean)\\] \\[\\mathbb{E}(perimeter\\_mean| concavity\\_mean) = β_0+ β_1(concavity\\_mean) + β_2(concavity\\_mean)^2\\]\n\\[\\begin{align*}\n\\mathbb{E}(perimeter\\_mean| concavity\\_mean) = \\beta_0+ \\beta_1(concavity\\_mean) + \\beta_2(concavity\\_mean)^2 + ... +\\\\ \\beta_{10}(concavity\\_mean)^{10}\n\\end{align*}\\]\nThe visualizations in Figures 10, 11, and 12 demonstrate that the more predictors are added, the more the models become overfit to the noise in our data. The model then loses its ability to generalize to new data.\nWe have trained and tested our data by creating an 80-20 train-test split. This ensures that there is a substantial amount of training data in order to evaluate a decently sized testing set.\nWe are implementing 10-fold, 8-fold, 5-fold and Leave One Out Cross-Validation. Each “held-out” fold is our test set. We are using Mean Absolute Error (MAE) as our error metric:\n\\[ \\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} \\left| y_i - \\hat{y}_i \\right|\\]\nWe are implementing cross-validation techniques to the following 2 models:\n\\[\\begin{align*}\n\\mathbb{E}(perimeter\\_mean | texture\\_mean, concavity\\_mean, smoothness\\_mean) = \\\\\n\\beta_0+ \\beta_1 (texture\\_mean) +\\beta_2(concavity\\_mean) + \\beta_3(smoothness\\_mean)\n\\end{align*}\\]\n\\[\\mathbb{E}(perimeter\\_mean| texture\\_mean, concavity\\_mean) = \\beta_0+ \\beta_1 (texture\\_mean) + \\beta_2(concavity\\_mean)\\]"
  },
  {
    "objectID": "test.html#logistic-regression",
    "href": "test.html#logistic-regression",
    "title": "STAT244SC Project",
    "section": "2. Logistic regression",
    "text": "2. Logistic regression\nLogistics regression is modeling method that allows us to adjust the linear regression model to account for binary categorical response variables by mapping probabilities between 0 and 1 to the real number range via ideas of logs and odds.\n\nThe formula for a sample logistics regression model with \\(n\\) predictors is\n\\[\nlog(odds(Y | X_1, X_2, ..., X_n)) = \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + ... + \\beta_nX_n,  \n\\]\nwhere Y represents the response variable with a binary outcome, and each \\(X_i\\) represents a quantitative explanatory variable.\nIn the context of our 4 variables of interest, our model evaluates to\n\\[\nlog(odds(Diagnosis | X_1, X_2, X_3, X_4) = \\beta_0 + \\beta_1X_1 + \\beta_2X_2  + \\beta_3X_3, \\beta_4X_4\n\\]\nwhere\n\n\\(X_1 =\\) perimeter_mean (mm)\n\\(X_2 =\\) texture_mean (pixel)\n\\(X_3 =\\) smoothness_mean (mm)\n\\(X_4 =\\) concavity_mean (mm)\n\\(Diagnosis\\) (1 - malignant, 0 - benign)\n\nBecause we are applying transformations on top of a regular linear regression model, there are adjustments to how we interpret the coefficients. Since this process is similar across all explanatory variables, we will only mathematically derive the interpretation for one of them for brevity.\nLet fix the value of a tumor’s \\(X_1, X_2, X_3, X_4\\) be some constants \\(a, b,c, d\\) respectively, then our model is as follows:\n\\[(eq1): log(odds(Diagnosis| X_1 = a, X_2 = b, X_3 = c, X_4 = d)) = \\] \\[\\beta_0 + \\beta_1a + \\beta_2b + \\beta_3c + \\beta_4d \\]\nIf we increase the value of \\(X_1\\) by 1, but keep all the other values the same, we would have equation 2 like so:\n\\[(eq2): log(odds(Diagnosis| X_1 = a+1, X_2 = b, X_3 = c, X_4 = d)) = \\] \\[\\beta_0 + \\beta_1(a+1) + \\beta_2b + \\beta_3c + \\beta_4d \\]\nIf we subtract eq1 from eq2, we would have \\[log(odds(Diagnosis| X_1 = a+1, X_2 = b, X_3 = c, X_4 = d)) - \\] \\[log(odds(Diagnosis| X_1 = a, X_2 = b, X_3 = c, X_4 = d)) = \\]\n\\[(\\beta_0 + \\beta_1(a+1) + \\beta_2b + \\beta_3c + \\beta_4d) - (\\beta_0 + \\beta_1a + \\beta_2b + \\beta_3c + \\beta_4d) \\]\nThis is equivalent to saying\n\\(log \\left( \\frac{\\operatorname{odds}(\\text{Diagnosis} \\mid X_1 = a+1, X_2 = b, X_3 = c, X_4 = d)}{\\operatorname{odds}(\\text{Diagnosis} \\mid X_1 = a, X_2 = b, X_3 = c, X_4 = d)} \\right) = \\beta_1\\)\nExponentiating both sides gives:\n\\[ \\frac{odds(Diagnosis| X_1 = a+1, X_2 = b, X_3 = c, X_4 = d)}{odds(Diagnosis| X_1 = a, X_2 = b, X_3 = c, X_4 = d)}= e^{\\beta_1} \\] We can rearrange this to:\n\\[ odds(Diagnosis| X_1 = a+1, X_2 = b, X_3 = c, X_4 = d)\\] \\[= e^{\\beta_1}odds(Diagnosis| X_1 = a, X_2 = b, X_3 = c, X_4 = d) \\]\nWe can interpret the above as for every 1 mm increase in the mean perimeter of the tumor ,the odds of it being malignant increases by a multiplicative factor of \\(e^{\\beta_1}\\) after adjusting for the mean texture, smoothness, and concavity.\nWe will apply this line of thinking to a section later on as we discuss the results of our model"
  },
  {
    "objectID": "test.html#k-means",
    "href": "test.html#k-means",
    "title": "STAT244SC Project",
    "section": "3. K-Means",
    "text": "3. K-Means\nK-means is an unsupervised learning algorithm that partitions the data into \\(k\\) clusters. In unsupervised learning, we have a set of random variables \\(X_1, \\ldots, X_p\\), each with \\(n\\) observed values. But, there is no response variable \\(Y\\).\nIn K-means, we choose an integer \\(K\\), which is the number of clusters, beforehand as a tuning parameter. Let \\(C_1, \\ldots, C_K\\) denote sets containing the indices of observations in each cluster.\nThe cluster sets must satisfy:\n\n\\(C_1 \\cup C_2 \\cup \\ldots \\cup C_K = \\{1, \\ldots, n\\}\\) (each observation belongs to some cluster)\n\\(C_i \\cap C_j = \\emptyset\\) for all \\(i \\neq j\\) (no observation belongs to more than one cluster)\n\nK-means seeks to minimize the total within-cluster variation:\n\\[\\min_{C_1,\\ldots,C_K} \\sum_{k=1}^{K} W(C_k)\\]\nwhere \\(W(C_k)\\) is the within-cluster variation for cluster \\(C_k\\), commonly defined using Euclidean distance:\n\\[W(C_k) = \\frac{1}{|C_k|} \\sum_{i,j \\in C_k} \\sum_{p=1}^{P} (x_{ip} - x_{jp})^2\\] where \\(X_{ij}\\) denotes the \\(i\\)th observation of predictor \\(X_j\\).\nThe algorithm aims to find cluster assignments that make observations within each cluster as similar as possible (minimizing within-cluster variation). Each cluster is represented by its centroid (mean of all points in the cluster), and observations are assigned to the nearest centroid.\nIn our breast cancer example, we’re clustering based on tumor characteristics (like radius_mean and texture_mean) to identify natural groupings that may correspond to malignant vs. benign tumors. We chose to have k=2 clusters as we are interested in differentiating between benign and malignant. The silhouette analysis in Figure 5 shows us that k=2 is the most optimal choice both, mathematically as well as for this given research question\nWe used the MSE as our measure of error as one of the main goals in K-means is to minimize the within cluster variation which is equivalent to the mean standard error (when using Euclidean distance)."
  },
  {
    "objectID": "test.html#cross-validation-1",
    "href": "test.html#cross-validation-1",
    "title": "STAT244SC Project",
    "section": "1. Cross-Validation",
    "text": "1. Cross-Validation\nThe table below displays evaluation metrics of cross-validation for our two models. As mentioned earlier, we used MAE as our error metric because it provides a fair and interpretable measure of error without disproportionately punishing large outliers, which makes it suitable for medical datasets such as this one, for breast cancer tumors.\n\n\n\n\n\n\n\n\n\n\n\nModel\nIn-sample MAE\n10-fold CV MAE\nLOOCV MAE\n5-fold CV MAE\n8-fold CV MAE\n\n\n\n\n1\n11.8729\n11.9542812\n11.95863\n11.9937511\n11.9305124\n\n\n2\n12.65028\n12.7211409\n12.73318\n12.7598652\n12.7120443\n\n\n\nFor Model 1, it looks like the MAE is roughly similar for when it’s measured in-sample (11.873) versus when it’s tested on “new” data (each test fold held out). Model 2 also has roughly similar MAE for in-sample (12.605) versus CV data. It seems better to pick the first model.\nThe CV errors seem to be fairly consistent between 10-fold, 5-fold, 8-fold and LOOCV. Although a slim difference, the 8-fold cross-validation measure provides the smallest CV error for both models."
  },
  {
    "objectID": "test.html#logistic-regression-1",
    "href": "test.html#logistic-regression-1",
    "title": "STAT244SC Project",
    "section": "2. Logistic Regression",
    "text": "2. Logistic Regression\nAccording to our model (Figure 13), all of our variables have a positive correlation to the response variable, meaning the greater the value, the higher the chances that a tumor is malignant.\nSpecifically, we have found that the odds of a tumor with a mean perimeter, mean standard deviation of gray-scale value of texture, mean variation in radius length, and mean severity of concave portions of the contour of the tumor of 0 is \\(e^{\\beta_0} = 8.244728*10^{-17}\\), which is comparatively low.\nFor every 1 mm increase in the mean perimeter of the tumor, the odds of it being malignant increases by a multiplicative factor of \\(e^{\\beta_1} = 1.207159\\) after adjusting for the mean texture, smoothness, and concativity.\nFor every 1 pixel increase in the mean standard deviation of gray-scale values of texture of the tumor ,the odds of it being malignant increases by a multiplicative factor of \\(e^{\\beta_2} = 1.444111\\) after adjusting for mean perimeter, smoothness and concavity.\nFor every 1 mm increase in the mean local variation in radius lengths of the tumor ,the odds of it being malignant increases by a multiplicative factor of a staggering \\(e^{\\beta_3} = 1.438568e*10^{46}\\) after adjusting for mean perimeter, texture, and concavity.\nFor every 1 mm increase in the mean of severity of concave portions of the contour of the tumor ,the odds of it being malignant increases by a multiplicative factor of a whooping \\(e^{\\beta_4} = 6.329209 *10^7\\) after adjusting for mean perimeter, texture, and smoothness."
  },
  {
    "objectID": "test.html#k-means-1",
    "href": "test.html#k-means-1",
    "title": "STAT244SC Project",
    "section": "3. K-Means",
    "text": "3. K-Means\nIn figure 8, the B cluster represents tumors with smaller mean radius and lower mean texture values. Therefore these are characteristics associated with breast mass tumors that are Benign. The M cluster represents tumors with larger mean radius and higher mean texture values. Therefore these are characteristics associated with breast mass tumors that are Malignant. The clustering we observed in figure 7 generally matches the clustering in figure 8 done via K-means on just texture_mean and radius_mean which had no info about whether tumours were benign or malignant."
  },
  {
    "objectID": "K-Means-Mini-Demo.html",
    "href": "K-Means-Mini-Demo.html",
    "title": "Lab: K-Means",
    "section": "",
    "text": "Getting Started\n\n\n\n\n\n\nDownload the .qmd file from Moodle and any needed .xlsx or .csv data files. Save these in the same folder/directory.\nOpen the Quarto file in RStudio: File &gt; Open File... &gt;. If you’re working on the MHC RStudio server, you need to upload the files first: go to the Files panel, then click Upload. Upload the .qmd file and any data files. You will need to upload each file one at a time.\nUpdate the author and date in the YAML header of this file.\nClick the Render button. If successful, you should have a new window pop up with a nice looking HTML document.\nFor this lab, you may need to still the package glmnet.\n\nAsk for help if you encounter issues on any of the steps above. Once you’ve successfully made it through these steps, you can continue.\n\n\n\n\nLoad Packages\nYou likely will need to install some these packages before you can run the code chunk below successfully.\n\nlibrary(tidyverse)\nlibrary(palmerpenguins)\nlibrary(factoextra)\nlibrary(amap)\n\n\n\nLoad Penguin Data\n\ndata(penguins)\nhead(penguins)\n\n# A tibble: 6 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           NA            NA                  NA          NA\n5 Adelie  Torgersen           36.7          19.3               193        3450\n6 Adelie  Torgersen           39.3          20.6               190        3650\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\n\n\nData Cleaning\n\n# Remove missing values\npenguins &lt;- penguins %&gt;% filter (!is.na(bill_length_mm) & !is.na(bill_depth_mm) & !is.na(species))\n\n# Make data table (named penguins_reduced) that only has\n# bill_length_mm and bill_depth_mm columns\npenguins_reduced &lt;- penguins %&gt;% select (bill_length_mm, bill_depth_mm)\n\n\n\nInitial Visualization\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm)) + \n  geom_point() \n\n\n\n\n\n\n\n\nWe’ll cluster these penguins based on their bill lengths and depths:\n\n\nImplement \\(K\\)-Means\nComplete the code below to run the K-means algorithm using K = 3.\n\nset.seed(244)\n# Run the K-means algorithm\nkmeans_3_round_1 &lt;- kmeans(scale(penguins_reduced), centers = 3) \n    \n# Plot the cluster assignments\npenguins_reduced %&gt;% \n  mutate(kmeans_cluster = as.factor(kmeans_3_round_1$cluster)) %&gt;%\n  ggplot(aes(x = bill_length_mm, y = bill_depth_mm, color = kmeans_cluster)) + \n  geom_point(size = 3) + \n  theme(legend.position = \"none\") + \n  labs(title = \"K-means with K = 3 (round 1)\") + \n  theme_minimal()\n\n\n\n\n\n\n\n\n\nWhy do we have to set the seed for K-means? In practice, why should we try out a variety of seeds?\n\nAnswer. We have seeds for reproduciability.\n\n\nK-Means Clusters Versus Known Species Groupings\n\n  ggplot(data = penguins, aes(x = bill_length_mm, y = bill_depth_mm, color = species)) + \n  geom_point(size = 3) + \n  theme(legend.position = \"none\") + \n  labs(title = \"Actual Groupings of Data Based on Species\") + \n  theme_minimal()\n\n\n\n\n\n\n\n\n\nVisually, how well do you think \\(K\\)-means captured the underlying species structure of the data?\n\nAnswer. YOUR ANSWER HERE\n\n\nTuning \\(K\\)\n\nTo implement K-means clustering we must choose an appropriate K! Use the following example to see the two different extreme situations. Typically, the ideal \\(K\\) is somewhere between the two extremes.\nMinimum: \\(K = 2\\) groups/clusters\nMaximum: \\(K = n\\) groups/clusters (one observation per cluster)\n\nWhat happens in the \\(K\\)-means algorithm if \\(K = n\\)?\nAnswer. YOUR ANSWER HERE\nLet’s consider anywhere from \\(K = 2\\) to \\(K = 20\\) clusters.\n\nset.seed(244)\n\nk_2  &lt;- kmeans(scale(penguins_reduced), centers = 2)\nk_20 &lt;- kmeans(scale(penguins_reduced), centers = 20)\n\npenguins_reduced %&gt;% \n  mutate(cluster_2 = as.factor(k_2$cluster)) %&gt;% \n  ggplot(aes(x = bill_length_mm, y = bill_depth_mm, color = cluster_2)) + \n    geom_point(size = 3) + \n    labs(title = \"K = 2\")\n\n\n\n\n\n\n\npenguins_reduced %&gt;% \n  mutate(cluster_20 = as.factor(k_20$cluster)) %&gt;% \n  ggplot(aes(x = bill_length_mm, y = bill_depth_mm, color = cluster_20)) + \n    geom_point(size = 3) + \n    labs(title = \"K = 20\") + \n    scale_color_manual(values = rainbow(20))\n\n\n\n\n\n\n\n\nWhat are your general impressions?\nAnswer. YOUR ANSWER HERE\n\n\nFinding Ideal K Value: Silhoutte\n\nThe average silhouette approach measures the quality of a clustering. That is, it determines how well each object lies within its cluster.\n\nTo do so, it maximizes the distance between clusters and minimizes distance within clusters.\n\nA high average silhouette indicates a good clustering.\nGiven a range of possible K values, the optimal number of clusters (K) is the one that maximizes the average silhouette.\n\nWe can use a built-in silhouette method in the fviz_nbclust function to compute the average silhouette for various K values.\n\nfviz_nbclust(scale(penguins_reduced), kmeans, method='silhouette')\n\n\n\n\n\n\n\n\nBased on the average silhouette approach, what is the optimal \\(K\\) value?\nAnswer. The optimal value for K appears to be K = 3.\n\n\nExperimenting with Distance Metrics\nWe can use the Kmeans method (notice the “K” is capitalized in this function name) from the amap library to specify how we are measuring distance in the K-means algorithm.\n\nset.seed(244)\nk_2_manattan = Kmeans(scale(penguins_reduced), centers = 3, \n                      method = \"manhattan\")\nk_2_euclid = Kmeans(scale(penguins_reduced), centers = 3, \n                    method = \"euclidean\")\nk_2_maxnorm = Kmeans(scale(penguins_reduced), centers = 3, \n                     method = \"maximum\")\n\n\n\nfviz_cluster(k_2_euclid, data = scale(penguins_reduced), \n             main = sprintf(\"K = %d Clusters w/ Manhattan Distance\", 3))\n\n\n\n\n\n\n\nfviz_cluster(k_2_manattan, data = scale(penguins_reduced),\n             main = sprintf(\"K = %d Clusters w/ Manhattan Distance\", 3))\n\n\n\n\n\n\n\nfviz_cluster(k_2_maxnorm, data = scale(penguins_reduced),\n             main = sprintf(\"K = %d Clusters w/ Manhattan Distance\", 3))\n\n\n\n\n\n\n\n\nTry changing \\(K\\) to equal 3$ in the code chunk above. How do the clusterings using the 3 distance metrics compare? What do you generally observe?\nAnswer. YOUR ANSWER HERE\nModify the code in the chunk above so that we can easily change the value of K (rather than making sure to change K manually in every line). In general coding practices, is called extracting out a constant."
  }
]